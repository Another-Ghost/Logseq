- 线程池最简单的实现形式是，采用**数目固定的[[工作线程]]**（往往与 `std::thread::hardware_concurrency()` 的返回值相等）。
  每当有任务需要处理时，我们便调用某个函数，将它放到[[任务队列]]中等待。各工作线程从队列中领取指定的任务并运行，然后再回到队列领取其他任务。
  最简易可行的线程池无法等待任务完成。若我们需要这么做，就得自己操控同步动作。
- 代码清单 1 展示了这种线程池的实现范例。
  ```cpp
  //list 1
  class thread_pool
  {
      std::atomic_bool done;
      thread_safe_queue<std::function<void()>> work_queue;  // 1
      std::vector<std::thread> threads;  // 2
      join_threads joiner;  // 3
  
      void worker_thread()
      {
          while (!done)  // 4
          {
              std::function<void()> task;
              if (work_queue.try_pop(task))  // 5
              {
                  task(); // 6
              }
              else
              {
                  std::this_thread::yield();  // 7
              }
          }
      }
  
  public:
      thread_pool() : done(false), joiner(threads)
      {
          unsigned const thread_count = std::thread::hardware_concurrency();  // 8
          try
          {
              for (unsigned i = 0; i < thread_count; ++i)
              {
                  threads.push_back(std::thread(&thread_pool::worker_thread, this));  // 9
              }
          }
          catch (...)
          {
              done = true;  // 10
              throw;
          }
      }
  
      ~thread_pool()
      {
          done = true;  // 11
      }
  
      template <typename FunctionType>
      void submit(FunctionType f)
      {
          work_queue.push(std::function<void()>(f));  // 12
      }
  };
  ```
- 这份实现把工作线程存放在一个 ``vector`` 容器内②，还采用了[[线程安全队列]] ① 来管理任务队列。本例假定使用者不必等待任务完成，且任务没有任何返回值，故可将它封装成 `std:function<void()>`的实例。无论向 `submit()` 传入的是函数还是可调用对象，都包装在一个 `std: function<void()>`实例内，再压入队列②。
  池内线程由构造函数启动：我们先调用 `std:thread::hardware_concurrency()`，得知硬件所支持的并发线程数目⑧，再如数创建线程，它们在成员函数 `worker_thread()` 中运行⑨。
- 线程的启动有可能因抛出[异常]([[异常安全]])而失败，若出现此情形，我们就需确保已启动的线程妥善终止，并将运行环境清理干净。妥善终止，并将运行环境清理干净。这项保障通过 `try/catch` 块实现 ⑩ ，每当有异常抛出，便设置标志 `done` 成立，还需采用[join_threads](((6633e66d-7ab5-487a-ba27-b846875700df))) 类 ③ ，由它的实例汇合全部线程。
  ```cpp
  struct join_threads
  {
  	std::vector<std::thread>& threads;
  public:
    	explicit join_threads(std::vector<std::thread>& threads_):
      threads(threads_)
    	{}
    	~join_threads()
    	{
      	for(unsigned long i=0; i<threads.size(); ++i)
      	{
        		if(threads[i].joinable())
          		threads[i].join();
  		} 
      }
  };
  ``````
  该保障还需析构函数配合：我们在其中设置 `done` 标志 ⑪ ，从而凭借 `join_threads` 类的实例确保全部线程均在线程池销毁之前完成运行。
  请注意，声明数据成员的先后次序十分重要：`done` 标志和 `work_queue` 队列必须位列最前①，接着是装载线程的 `vector` 容器实例 `threads`②，`joiner` 则必须在最后声明③。这是为了确保线程池的数据成员能正确地依次销毁：本例中，线程必须全部终结，[[任务队列]]才可以销毁。
- `worker_thread()` 函数本身相当简单：各线程通过它反复从队列中取出任务⑤，并同时执行⑥，只要 `done` 标志未被设置为成立就一直循环④。假如队列中没有任务，该函数便调用 `std::his_thread::yield()`令当前线程稍事歇息⑦，好让其他线程把任务放入队列，随后它再切换回来，继续下一轮循环，尝试从队列中领取任务运行。
- 上述简易可行的线程池足以达成多种目的，尤其适合具有下列特点的任务：**彼此完全独立，也没有任何返回值，且不执行阻塞操作**。
  但是还存在许多情况，该线程池无法满足所需，而在另一些情况下，它还会导致问题，譬如死锁。
  再者，对于简单的问题，更好的做法可能是采用 `std:async()` 这种方式。
- ## 等待提交给线程池的任务完成运行
	- 如果主线程需要某任务的计算结果，就会面临一种特殊情况，它必须等待生成的线程完成任务。
	  针对这种情况，运用 `future` 即可将**等待**和**传递结果**两个操作**合二为一**。
	- 代码清单 2 实现的线程池做了必要修改，让我们得以等待任务完成，再把它的返回值传递给正在等待的线程。
	  ```cpp
	  #include <deque>
	  #include <future>
	  #include <memory>
	  #include <functional>
	  #include <iostream>
	  #include <iostream>
	  
	  class function_wrapper
	  {
	      struct impl_base {
	          virtual void call()=0;
	          virtual ~impl_base() {}
	      };
	      std::unique_ptr<impl_base> impl;
	      template<typename F>
	      struct impl_type: impl_base
	      {
	          F f;
	          impl_type(F&& f_): f(std::move(f_)) {}
	          void call() { f(); }
	      };
	  public:
	      template<typename F>
	      function_wrapper(F&& f):
	          impl(new impl_type<F>(std::move(f)))
	      {}
	  
	      void call() { impl->call(); }
	  
	      function_wrapper(function_wrapper&& other):
	          impl(std::move(other.impl))
	      {}
	  
	      function_wrapper& operator=(function_wrapper&& other)
	      {
	          impl=std::move(other.impl);
	          return *this;
	      }
	  
	      function_wrapper(const function_wrapper&)=delete;
	      function_wrapper(function_wrapper&)=delete;
	      function_wrapper& operator=(const function_wrapper&)=delete;
	  };
	  
	  class thread_pool
	  {
	  public:
	      std::deque<function_wrapper> work_queue;    //1
	  
	      template<typename FunctionType>
	      std::future<typename std::result_of<FunctionType()>::type> submit(FunctionType f)   //2
	      {
	          typedef typename std::result_of<FunctionType()>::type result_type;  //3
	          
	          std::packaged_task<result_type()> task(std::move(f));   //4
	          std::future<result_type> res(task.get_future());    //5
	          work_queue.push_back(std::move(task));  //6
	          return res; //7
	      }
	      // rest as before
	  };
	  
	  ``` 
	  由于 [[std::packaged_ task]] 的实例**仅能移动**而**不可复制**，但[[std::function]] 要求本身所含的函数对象能进行拷贝构造，因此任务队列的元素无法再用 `std::function<>` 充当。
	  我们必须定制自己的类作为代替，以包装函数，并处理只移型别。这个类其实就是一个包装可调用对象的简单类，对外可消除该对象的型别。这个类还具备函数调用操作符。在代码清单 2 实现的线程池中，我们仅需处理一种函数，它不接收参数，且返回 `void` 。因此，这个新实现把任务直接当作[[虚拟调用]]处理。
	- 首先，我们调用修改过的 `submit()` ②。这个函数返回一个 `std::future<>`实例, 任务的返回值由它持有，调用者凭借该实例即可等待任务完成。所给出的函数 `f()` 的返回值型别要求预先明确, 于是代码引入了 `std::result_of<FunctionType>` 的实例即为函数 `f()` , 它不接收参数、而其运行结果的型别是 `std::result_of<FunctionType()>::type` 。
	- 然后，我们把函数 `f()` 包装在 `std::packaged_task<result_type()>`中 ④ , 因为 `f()`  是函数或可调用对象，不接收参数，返回值是 `result_type` 型别的实例。根据推导，两者依此相符。
	  接着，我们从 `std::packaged_task` 取得对应的 `future` ⑤, 然 后将任务压入队列 ⑥ , 再向 `submit()` 的调用者返回 `future` ⑦。
	  请注意, 由于 `std::packaged_task` 不可复制, 因此一定要通过 `std::move()` 把任务压入队列。
	  照此修改, 任务队列存储的元素是 `function_ wrapper` 对象, 而不再是 `std::function<void()>` 对象。现在, 线程池遂能够依从前文的新方式处理任务。
	- 代码清单 3 中的 `parallel_accumulate()` 函数采用了代码清单 2 中的线程池实现。
	  ```cpp
	  #include <vector>
	  #include <future>
	  #include <thread>
	  
	  template<typename Iterator,typename T>
	  T parallel_accumulate(Iterator first,Iterator last,T init)
	  {
	      unsigned long const length=std::distance(first,last);
	  
	      if(!length)
	          return init;
	  
	      unsigned long const block_size=25;
	      unsigned long const num_blocks=(length+block_size-1)/block_size; //1
	  
	      std::vector<std::future<T> > futures(num_blocks-1);
	      thread_pool pool;
	  
	      Iterator block_start=first;
	      for(unsigned long i=0;i<(num_threads-1);++i)
	      {
	          Iterator block_end=block_start;
	          std::advance(block_end,block_size);
	          futures[i]=pool.submit(accumulate_block<Iterator,T>());//2
	          block_start=block_end;
	      }
	      T last_result=accumulate_block()(block_start,last);
	      T result=init;
	      for(unsigned long i=0;i<(num_blocks-1);++i)
	      {
	          result+=futures[i].get();
	      }
	      result += last_result;
	      return result;
	  }
	  ```
	- 程序依据“块的数量”（num_blocks①）划分任务，而非线程数目。我们需要把数据分成块，其体积是值得并发处理的最小尺寸，以便将线程池的可伸缩性利用到极致。当池中只有少量线程时，每个线程都会处理许多数据块，但如果硬件线程的数目有所增加，并行处理的块的数目也会随之变大。
		- 我们需要小心选择“值得并发处理的数据块的最小尺寸”。向线程池提交任务、交给工作线程执行、通过 `std::future` 返回结果等操作均附带固有的额外开销，小任务因此得不偿失。若选择的任务规模过小，线程池的运行速度也许比单线程还慢。
	- 如果数据块尺寸合理，那我们就不必操劳包装任务、获取 `furure`，或为了以后汇合线程而保存 `std::thread` 对象，线程池自会打点一切。我们需要做的全部事情仅仅是调用 `submit()` 提交任务②。
	- 这个线程池还顾及了[异常安全]([[并行算法代码中的异常安全]])。如果池中任务抛出任何异常，就会通过 `submit()` 返回的 `future` 向外传播。若该函数因发生异常而退出，线程池的析构函数便丢弃尚未完成的任务，等待池内线程自行结束。
	- 上例属于简单情况，各任务彼此独立，所示的线程池运作顺畅。但在其他情况下，某些任务依赖于别的任务，而两者都提交给了线程池，事情就不妙了。
- ## 等待其他任务完成的任务
	- 以快速排序算法举例。线程数量毕竟有限，若耗尽了空闲线程，就可能令它们最终全都停滞不前，空等那些尚待调度执行的任务（可能发生[[死锁]]）。因此，我们需要采用的解决方法与第 8 章相似：在等待目标数据块完成操作的过程中，主动处理相关的还未排序的数据块。
	  若采用线程池管理任务列表及其关联线程，则完全不必直接访问[[任务列表]]就能达到目的，这正是线程池的意义所在。我们需要做的是修改线程池，让其自动按上述模式操作。
	- 线程数量毕竟有限，若耗尽了空闲线程，就可能令它们最终全都停滞不前，空等那些尚待调度执行的任务。因此，我们需要采用的解决方法与第8章相似：在等待目标数据块完成操作的过程中，主动处理相关的还未排序的数据块。
	  若采用线程池管理任务列表及其关联线程，则完全不必直接访问任务列表就能达到目的，这正是线程池的意义所在。我们需要做的是修改线程池，让其自动按上述模式操作。
	  最简单的方法之一是在 `thread_pool` 类上增加一个新函数，负责运行队列中的任务，并自行管控“领取任务并执行”的循环。下面将深入解说这个函数。
	  高级的线程池为了实现这项功能，也许会向等待函数加入控制逻辑，或者增加其他形式的等待函数，从而给尚待执行的任务划分优先级。
	  代码清单 4 展示了新增的 `run_pending_task()` 函数，代码清单 5 则利用该函数改进了快速排序的代码。
	  ```cpp
	  // list 4
	  void thread_pool::run_pending_task()
	  {
	      function_wrapper task;
	      if(work_queue.try_pop(task))
	      {
	          task();
	      }
	      else
	      {
	          std::this_thread::yield();
	      }
	  }
	  ```
	- ```cpp
	  // list 5 
	  #include <list>
	  #include <algorithm>
	  #include <vector>
	  
	  template<typename T>
	  struct sorter
	  {
	      thread_pool pool;
	      
	      std::list<T> do_sort(std::list<T>& chunk_data)
	      {
	          if(chunk_data.empty())
	          {
	              return chunk_data;
	          }
	          
	          std::list<T> result;
	          result.splice(result.begin(),chunk_data,chunk_data.begin());
	          T const& partition_val=*result.begin();
	      
	          typename std::list<T>::iterator divide_point=
	              std::partition(
	                  chunk_data.begin(),chunk_data.end(),
	                  [&](T const& val){return val<partition_val;});
	  
	          std::list<T> new_lower_chunk;
	          new_lower_chunk.splice(
	              new_lower_chunk.end(),
	              chunk_data,chunk_data.begin(),
	              divide_point);
	      
	          thread_pool::task_handle<std::list<T> > new_lower=
	              pool.submit(
	                  std::bind(
	                      &sorter::do_sort,this,
	                      std::move(new_lower_chunk)));
	      
	          std::list<T> new_higher(do_sort(chunk_data));
	          
	          result.splice(result.end(),new_higher);
	          while(!new_lower.is_ready())
	          {
	              pool.run_pending_task(); // 空闲的等待线程会在这里领任务执行
	          }
	          
	          result.splice(result.begin(),new_lower.get());
	          return result;
	      }
	  };
	  
	  
	  template<typename T>
	  std::list<T> parallel_quick_sort(std::list<T> input)
	  {
	      if(input.empty())
	      {
	          return input;
	      }
	      sorter<T> s;
	      
	      return s.do_sort(input);
	  }
	  ```
- ## 避免[[任务队列]]上的争夺
	- 线程池仅具备一个任务队列供多线程共用，在同一个线程池实例上，每当有线程调用`submit()` ，就把新任务压入该队列。类似地，为了执行任务，工作线程不断从这一队列弹出任务。
	- 因此，队列上的争夺行为随着处理器数目的增多而加剧。这是实打实的性能损失，即便我们利用无锁队列避开显式等待，仍然会产生 缓存乒乓 现象，导致浪费时间。
	- 有一种方法可解决[[缓存乒乓]]：为每个线程配备独立的任务队列。**各线程只在自己的队列上发布新任务，仅当线程自身的队列没有任务时，才会从全局队列领取任务**。代码清单 6 展示了一个线程池实现，其中采用了 [[thread_local]] 变量，从而令每个线程都具有自己的任务队列，线程池本身则再维护一^^全局队列^^。
	- ```cpp
	  class thread_pool
	  {
	      thread_safe_queue<function_wrapper> pool_work_queue;
	  
	      typedef std::queue<function_wrapper> local_queue_type; //1
	      static thread_local std::unique_ptr<local_queue_type> //2
	          local_work_queue;
	     
	      void worker_thread()
	      {
	          local_work_queue.reset(new local_queue_type); //3 初始化
	          
	          while(!done)
	          {
	              run_pending_task();
	          }
	      }
	  
	  public:
	      template<typename FunctionType>
	      std::future<std::result_of<FunctionType()>::type>
	          submit(FunctionType f)
	      {
	          typedef std::result_of<FunctionType()>::type result_type;
	          
	          std::packaged_task<result_type()> task(f);
	          std::future<result_type> res(task.get_future());
	          if(local_work_queue) //4
	          {
	              local_work_queue->push(std::move(task));
	          }
	          else
	          {
	              pool_work_queue.push(std::move(task)); //5
	          }
	          return res;
	      }
	  
	      void run_pending_task()
	      {
	          function_wrapper task;
	          if(local_work_queue && !local_work_queue->empty()) //6
	          {
	              task=std::move(local_work_queue->front());
	              local_work_queue->pop();
	              task();
	          }
	          else if(pool_work_queue.try_pop(task)) //7
	          {
	              task();
	          }
	          else
	          {
	              std::this_thread::yield();
	          }
	      }
	      // rest as before
	  };
	  ```
	- 线程局部的任务队列由 `std:unique_ptr` 指针持有 ② ，该队列先在 `worker_thread()` 函数中完成初始化 ③ ，再进入处理任务的循环。
	- 接着，由 `submit()` 判别当前线程是否具备任务队列④。若具备，它即为池内线程，我们可把任务放人局部队列；否则，就应照旧将任务加入线程池所属的全局队列⑤。
	- `run_pending_task()`也进行了相似的判别，但我们还需验明局部队列中是否含有任务
	  ⑥，若有，就取出第一项任务来处理（请注意，该局部队列可由普通的 `std:queue` 队列充当①，因为它始终只被唯—一个线程访问）；若无，则依旧试图从线程池的全局队列领取任务⑦。
	- 上述方法很好地减少了争夺，却很容易因任务分配不均而导致事与愿违：某一线程“疲于奔命”，其他线程却无所事事。以快速排序代码举例，若一个线程负责处理多块数据，它可能只将最顶层的那个数据块放入全局队列，而把剩下的数据块全加到自身的局部队列中。这违背了使用线程池的初衷。
	  万幸，我们可以对症下药：若全局队列和线程自身的局部队列均空无一物，便让线程从别人的队列窃取任务。
- ## [[任务窃取]]
	- 我们终于完善了线程池，把它提升至实战高度，它极具潜力，足以胜任多种用途。
	  针对任意一种具体的应用方式，这个线程池都存在无数改进方法，我们将其留给读者作练习。有一个方面我们尚未深入探讨：动态调整线程池规模以求 CPU 的使用效率最优，其中甚至包括处理线程发生阻塞的情形，如等待 I/O 完成或等待互斥解锁。
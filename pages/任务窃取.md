- 虽然我们能够编写无锁队列，令其隶属的线程在一端压入和弹出任务，让其他线程在另一端同时窃取任务，但这种队列的实现超出了本书范畴。本节意在阐明任务窃取的思想，依旧采用互斥保护队列数据。我们期望**任务窃取鲜有发生，互斥上很少出现争夺**，从而得以尽量降低操作该简易队列的额外开销。代码清单 7 展示了一个基于锁的队列的简单实现。
- ```cpp
  class work_stealing_queue
  {
  private:
      typedef function_wrapper data_type;
      std::deque<data_type> the_queue; //1
      mutable std::mutex the_mutex;
      
  public:
      work_stealing_queue()
      {}
  
      work_stealing_queue(const work_stealing_queue& other)=delete;
      work_stealing_queue& operator=(
          const work_stealing_queue& other)=delete;
  
      void push(data_type data) //2
      {
          std::lock_guard<std::mutex> lock(the_mutex);
          the_queue.push_front(std::move(data)); //前端
      }
  
      bool empty() const
      {
          std::lock_guard<std::mutex> lock(the_mutex);
          return the_queue.empty();
      }
  
      bool try_pop(data_type& res) //3
      {
          std::lock_guard<std::mutex> lock(the_mutex);
          if(the_queue.empty())
          {
              return false;
          }
          
          res=std::move(the_queue.front()); //前端
          the_queue.pop_front();
          return true;
      }
  
      bool try_steal(data_type& res) //4
      {
          std::lock_guard<std::mutex> lock(the_mutex); 
          if(the_queue.empty())
          {
              return false;
          }
          
          res=std::move(the_queue.back()); //后端
          the_queue.pop_back();
          return true;
      }
  };
  
  ```
- 这一队列是 `std:queue<function_wrapper>` 的简单包装①，它采用互斥锁保护所有访问。`push()` ② 和 `try_Pop()` ③ 都操作队列的前端，而 `try_steal()` ④则操作队列的后端。
	- 就其所属的线程而言，该“队列”其实是个后进先出的栈容器：最后压入队列的数据会被最先取出。从缓存的视角来看，这有助于性能改进，原因是对比早前的任务向队列压人的数据，与现行任务相关的数据更有可能还留在[[缓存]]内。
	- 再者，这很好地契合了快速排序这一类算法。前文的实现范例在每次调用 `do_sort()` 时，都会往栈容器压入一项任务，再等待它完成。我们总是先处理最近压入的任务，以保证，最先处理完成当前调用顾需的數据块，然后才轮到其他执行分支需要的数据块，从而减少活动的任务的数量及钱的总使用量。
	- `try_steal()` 从队列的另一端（与 `try_Pop()` 相对）领取任务，以尽量减少爭夺。
- 接下来，代码清单 8 展示了窃取任务应用于线程池中的一个可行的实现。
  ```cpp
  #include <vector>
  #include <atomic>
  #include <thread>
  class thread_pool
  {
      typedef function_wrapper task_type;
      
      std::atomic_bool done;
      thread_safe_queue<task_type> pool_work_queue;
      std::vector<std::unique_ptr<work_stealing_queue> > queues; //1
      std::vector<std::thread> threads;
      join_threads joiner;
  
      static thread_local work_stealing_queue* local_work_queue; //2
      static thread_local unsigned my_index;
     
      void worker_thread(unsigned my_index_)
      {
          my_index=my_index_;
          local_work_queue=queues[my_index].get(); //3
          while(!done)
          {
              run_pending_task();
          }
      }
  
      bool pop_task_from_local_queue(task_type& task)
      {
          return local_work_queue && local_work_queue->try_pop(task);
      }
  
      bool pop_task_from_pool_queue(task_type& task)
      {
          return pool_work_queue.try_pop(task);
      }
  
      bool pop_task_from_other_thread_queue(task_type& task) //4
      {
          for(unsigned i=0;i<queues.size();++i)
          {
              unsigned const index=(my_index+i+1)%queues.size(); //5
              if(queues[index]->try_steal(task))
              {
                  return true;
              }
          }
          
          return false;
      }
  
  public:
      thread_pool():
          joiner(threads),done(false)
      {
          unsigned const thread_count=std::thread::hardware_concurrency();
  
          try
          {
              for(unsigned i=0;i<thread_count;++i)
              {
                  queues.push_back(std::unique_ptr<work_stealing_queue>(
                                       new work_stealing_queue)); //6 线程池统一创建并分配local队列
                  threads.push_back(
                      std::thread(&thread_pool::worker_thread,this,i));
              }
          }
          catch(...)
          {
              done=true;
              throw;
          }
      }
      
      ~thread_pool()
      {
          done=true;
      }
  
      template<typename ResultType>
      using task_handle=std::unique_future<ResultType>;
  
      template<typename FunctionType>
      task_handle<std::result_of<FunctionType()>::type> submit(
          FunctionType f)
      {
          typedef std::result_of<FunctionType()>::type result_type;
          
          std::packaged_task<result_type()> task(f);
          task_handle<result_type> res(task.get_future());
          if(local_work_queue)
          {
              local_work_queue->push(std::move(task));
          }
          else
          {
              pool_work_queue.push(std::move(task));
          }
          return res;
      }
  
      void run_pending_task()
      {
          task_type task;
          if(pop_task_from_local_queue(task) ||		//7
             pop_task_from_pool_queue(task) || 		//8
             pop_task_from_other_thread_queue(task)) 	//9
          {
              task();
          }
          else
          {
              std::this_thread::yield();
          }
      }
  };
  ```
- `pop_task_from_other_thread_queue`（逐个访问池内线程所含的全部队列 ④ ，试图从中窃取任务。这些线程在开始窃取任务时，均根据自己在清单中的索引值，向后偏移一项，以下一线程作为窃取起始点⑤，借此避免了清单中的头一个队列沦为“众矢之的”，而导致每个线程都集中对其下手。